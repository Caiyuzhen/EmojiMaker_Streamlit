import streamlit as st
from src.Config import Config
import requests
from openai import OpenAI


INFO = "â„¹ï¸ Open AI key æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥"


def request_llm_custom_msg(
	api_key,
	inputMsg,
	temperature,
	server_url,
	model,
	max_tokens,
):
	# ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯åŠ è½½æ¨¡å‹
	client = OpenAI(base_url=server_url, api_key=api_key)
	try:
		completion = client.chat.completions.create(
			api_key=api_key,
			temperature=temperature, # æ¨¡å‹è¾“å‡ºçš„åˆ›æ„ç¨‹åº¦ (éšæœºæ€§)
			server_url=server_url,
			model=model,
			messages=[
				{"role": "system", "content": "Please answer the user's question."},
				{"role": "user", "content": inputMsg},
			],
			max_tokens=max_tokens,
		)
		# è¿”å›æ¨¡å‹çš„å›ç­”
		return completion.choices[0].message['content'], "OK ğŸ‘"
	except Exception as e:
			return f"Error: {str(e)}", "â›”"